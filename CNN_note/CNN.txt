#############
# CNN
#############

https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C

## computer vision problem
- image classification
- object detection
- neural style transfer

## convolution neural network (CNN)
- image data * filter 
- filter scan the image data and then calculate weighted avg(convolution)
- vertical edge filter 
1 0 -1    1 0 -1 Sobel filter
1 0 -1    2 0 -2
1 0 -1    1 0 -1

- python: conv-forward
- tensorflow: tf.nn.conv2d
- keras: conv2D

- padding
--Problem: shrinking output; throw away a lot of info from edge.
--nxn * fxf = (n-f+1)x(n-f+1)  (no padding: "valid", f is usually odd)
            = (n+2p-f+1)x(n+2p-f+1) (with padding pxp: "same" means output size = input size)
            
- stride
-- filter moving steps: s
-- nxn * fxf = floor[(n+2p-f)/s + 1] x floor[(n+2p-f)/s + 1]  

- Converlution over vol
--3 chanel image need 3 filters, chanels dim need to match
  e.g 6x6x[3] image 3x3x[3] filter = each output is 27(3x3x3) number weighted avg
  nxnxn_c  *  fxfxn_c = (n-f+1) x (n-f+1) x n_c' (# of filters, for vert edge, horz edge)
  
 = 1 layer CNN
 - Z[i] = W[i]A[i-1] + b[i]
         = filter*image + biase correction
       
 - A[i] = activation(Z[i])
         = ReLU(output from multiple filters)
  
 - Notation see CNN_notation1      
 
 = Deep CNN
 - see CNN_ex
 
 - as layer goes deeper
 -- size of filter decrease 
 -- # of filter increase
 
 - type of layer
 --Convolution (CONV)
 --Pooling (POOL): no parameters, does not impact gradient decent
 --Fully connected (FC)
 
 = Pooling layer
 - max pooling (if a feature is detected in a region, keep this region # high, o.w. low)
 - average pooling
 - hyperparas: filter size, stride, Max or avg pooling (no padding usually)
 
 = CNN pars
 - Pooling layer no par
 - CONV has small # of par
 - FC layer has large # of par
 
 = Why CONV
 - parameter sharing: through parameter sharing, the # of pars reduce significantly
 - Sparcity of connections (not fully connected)
 
 = softmax function (normalized exponential function)
 https://en.wikipedia.org/wiki/Softmax_function
 In mathematics, the softmax function, or normalized exponential function, is a generalization of the logistic function that "squashes" a K-dimensional vector {\displaystyle \mathbf {z} } \mathbf {z}  of arbitrary real values to a K-dimensional vector {\displaystyle \sigma (\mathbf {z} )} \sigma (\mathbf {z} ) of real values in the range [0, 1] that add up to 1.
 
 

 
